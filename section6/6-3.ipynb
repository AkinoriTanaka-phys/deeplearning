{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class Control_print():\n",
    "    ''' model.summary() が巨大すぎるとき\n",
    "        >>> C = Control_print(fst=初め何行目まで表示するか, lst=最後何行目から表示するか)\n",
    "        >>> model.summary(print_fn=C.omitted_print)\n",
    "        で省略表示'''\n",
    "    def __init__(self, maxcount=1000, fst=10, lst=321):\n",
    "        self.counter = iter(np.arange(maxcount))\n",
    "        self.fst = fst\n",
    "        self.lst = lst\n",
    "        self.show_dots = True\n",
    "        \n",
    "    def omitted_print(self, x):\n",
    "        line = self.counter.__next__()\n",
    "        if line < self.fst or line > self.lst:\n",
    "            print(x)\n",
    "        elif line==self.lst:\n",
    "            print(\"... {} layers ...\".format(line - self.fst))\n",
    "            print(\"_\"*98)\n",
    "            self.show_dots = False\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "class CNNModel(tf.keras.Model): # モデル設計\n",
    "    def __init__(self, T=1):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.c11 = tf.keras.layers.Conv2D(16, (3,3), padding='same', activation='relu')\n",
    "        self.c12 = tf.keras.layers.Conv2D(16, (3,3), padding='same', activation='relu')\n",
    "        self.dr1 = tf.keras.layers.Dropout(0.25)\n",
    "        self.p1  = tf.keras.layers.MaxPooling2D((2, 2))\n",
    "\n",
    "        self.c21 = tf.keras.layers.Conv2D(32, (3,3), padding='same', activation='relu')\n",
    "        self.c22 = tf.keras.layers.Conv2D(32, (3,3), padding='same', activation='relu')\n",
    "        self.dr2 = tf.keras.layers.Dropout(0.25)\n",
    "        self.p2  = tf.keras.layers.MaxPooling2D((2, 2))\n",
    "\n",
    "        self.flat = tf.keras.layers.Flatten()\n",
    "        self.l1 = tf.keras.layers.Dense(128,activation = \"relu\")\n",
    "        self.dr3= tf.keras.layers.Dropout(0.5)\n",
    "        self.l2 = tf.keras.layers.Dense(10)\n",
    "        self.sigma = tf.keras.layers.Activation('softmax')\n",
    "\n",
    "        self.T = 1\n",
    "        \n",
    "    def call(self, x):\n",
    "        h = self.c11(x)\n",
    "        h = self.c12(h)\n",
    "        h = self.dr1(h)\n",
    "        h = self.p1(h)\n",
    "\n",
    "        h = self.c21(h)\n",
    "        h = self.c22(h)\n",
    "        h = self.dr2(h)\n",
    "        h = self.p2(h)\n",
    "\n",
    "        h = self.flat(h)\n",
    "        h = self.l1(h)\n",
    "        h = self.dr3(h)\n",
    "        h = self.l2(h)\n",
    "        return self.sigma(h/self.T)\n",
    "    \n",
    "    def summary(self, print_fn):\n",
    "        x = tf.keras.Input(shape=(32, 32, 3))\n",
    "        return (tf.keras.Model(inputs=x, outputs=self.call(x))).summary(print_fn=print_fn)\n",
    "        \n",
    "def one_hot(y):\n",
    "    out = np.zeros(10)\n",
    "    out[y] = 1\n",
    "    return out\n",
    "\n",
    "def prob(model, x):\n",
    "    x = x.reshape(1,32,32,3).astype(np.float32)\n",
    "    y = model(x).numpy().reshape(10)\n",
    "    return y\n",
    "\n",
    "def batch_step(X, Y, model, optimizer): # 学習ステップ\n",
    "    with tf.GradientTape() as tape:\n",
    "        Y_pred = model(X) \n",
    "        loss_value = L(Y, Y_pred) \n",
    "    grads = tape.gradient(loss_value, model.trainable_variables) \n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    return loss_value\n",
    "    \n",
    "def return_tf_batch(X, Y, batch_size): # バッチ処理\n",
    "    X_32bits, Y_32bits = X.astype(np.float32), Y.astype(np.float32)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X_32bits, Y_32bits))\n",
    "    dataset = dataset.shuffle(len(X), reshuffle_each_iteration=False) \n",
    "    return dataset.batch(batch_size=batch_size).as_numpy_iterator()\n",
    "\n",
    "def measure(model, X_test, Y_test):\n",
    "    return np.mean(np.argmax(model.predict(X_test), axis=1) == Y_test.reshape(10000))\n",
    "        \n",
    "##### CIFAR-10 #####\n",
    "cifar10 = tf.keras.datasets.cifar10 \n",
    "(X, Y), (X_test, Y_test) = cifar10.load_data()\n",
    "X, X_test = X/255, X_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-3. 転移学習\n",
    "ここまで、機械学習を使う際には、訓練と実践の2種類のパターンがあることを大前提として説明してきました。機械学習の目的は\n",
    "\n",
    "* データ生成確率 $p({\\bf x})$, $p(y|{\\bf x})$ があって\n",
    "* モデル確率 $q({\\bf x}), q(y|{\\bf x})$ をこれらに近づける\n",
    "\n",
    "ことで、そうすれば $p$ の振る舞いを予言することができるという理屈でした。このことは暗黙のうちに、**訓練と実践でデータが従う確率分布が同じ**であることを仮定しています。しかし、場合によっては訓練で手に入るデータと実践データが異なる場合も有りますし、ここまで説明してきたようなきれいな設定が適用できるケースはむしろ稀でしょう。**転移学習(transfer learning)** はここまでの機械学習の設定をより一般化した、機械学習を定式化するより広い枠組みであり、これから益々重要になってくる考え方だと思います。そこでこの節では、転移学習におけるいくつかの用語（分野が盛り上がり始めてから日が浅いためか様々な用語が散在）を説明し、教師あり学習の文脈での転移学習の例をデモンストレーションします。\n",
    "\n",
    "### ドメイン\n",
    "教師あり学習では、入力 ${\\bf x}$、出力 $y$ (これは必ずしもスカラー値とは限らないけれど、見た目で区別しやすいので太字にはしない）がそれぞれ\n",
    "\n",
    "* ${\\bf x}$ は何らかの（入力）データ生成確率 $p_X({\\bf x})$ に従う。ここで $X$ は ${\\bf x}$ が属する空間\n",
    "* $y$ も何らかの（教師信号）データ条件付き確率 $p_{Y|X}(y|{\\bf x})$ に従う。ここで $Y$ は $y$ が属する空間\n",
    "\n",
    "としていました。これはもちろん、\n",
    "\n",
    "$$\n",
    "p_{X, Y}({\\bf x},y) =  p_{Y|X}(y|{\\bf x})p_X({\\bf x})\n",
    "$$\n",
    "\n",
    "の存在を仮定して周辺化しても同じです。データ=$({\\bf x}, y)$ の住む空間＝$X \\times Y$ と、その上の確率分布 $p_{X, Y}$ の組のことを、**ドメイン(domain)** と呼びます。例えば\n",
    "\n",
    "- **MNIST(ラベル付き)のドメイン：**\n",
    "    - $X = \\mathbb{R}^{28 \\times 28 \\times 1}, Y = \\{0,1,2, \\dots, 9\\}$として、$p_X({\\bf x})=$28x28のグレイスケール手書き数字の画像生成確率、$p_{Y|X}(y|{\\bf x})=$画像を見て、どの数字か認識する確率\n",
    "- **CIFAR-10(ラベル付き)のドメイン：**\n",
    "    - $X = \\mathbb{R}^{32 \\times 32 \\times 3}, Y = \\{\\text{飛行機}(0), \\text{自動車}(1), \\text{鳥}(2), \\dots, \\text{トラック}(9)\\}$として、$p_X({\\bf x})=$32x32x3のRGBカラー画像の生成確率、$p_{Y|X}(y|{\\bf x})=$画像を見て、どのラベルか認識する確率\n",
    "    \n",
    "といった具合です。\n",
    "\n",
    "### 転移学習の目標\n",
    "例えば、$(X\\times Y, p_{X \\times Y})$ をMNIST(ラベル付き)のドメインとして、このドメインからのサンプリング（データ）は手に入るわけですが、それを\n",
    "\n",
    "- **近所の郵便局に運び込まれるハガキの郵便番号ドメイン**\n",
    "\n",
    "と同じという保証は全くありません。実際、どのように郵便番号を電子化するかによって画像サイズも変わりますし、チャネル数も変わります。これは $X$ の変化ですが、$p_X$、つまり出てくる画像の従う確率分布も日本とアメリカの人々の手癖は違うでしょうから異なりますし、そこが異なると当然どの画像を7と判断すべきかのルール $p_{Y|X}$ も変わってくるでしょう。\n",
    "\n",
    "このように、元とするドメイン（**ソース・ドメイン**）と運用したい先の目標のドメイン（**ターゲット・ドメイン**）は異なるのが一般的です。転移学習では、ソース・ドメインの情報（データや訓練モデルなど）を用いて、ターゲット・ドメインでの汎化を目的とします：\n",
    "\n",
    "$$\n",
    "\\text{source domain} \\to \\text{Generalization(target domain)}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "これまで、アヤメデータやMNIST、CIFAR-10での実験は全てソース＝ターゲットの前提の元で説明していましたから、これまでの話は転移学習の特殊な場合に含まれると言えます。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 簡単なデモンストレーション\n",
    "これまで紹介してこなかった気がしますが、画像系のデータベースで最大規模のものに**ImageNet**と呼ばれるものがあります。これは入力画像データはまちまちですが、高画質の画像と、それに1,000ラベルが着けられた、およそ100万個のサンプルから成るデータベースです。画像認識ニューラルネットワークのState-Of-The-Artモデルの多くは、このデータセットで訓練されたモデルパラメータを公開しています。例えば以下では [arXiv:1801.04381](https://arxiv.org/abs/1801.04381) で提案された、軽量なImageNet訓練済みモデルのMobileNetV2を（初回はダウンロードして）読み込むコマンドです："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mobilenetv2_1.00_96\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_14 (InputLayer)           [(None, 96, 96, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_pad (ZeroPadding2D)       (None, 97, 97, 3)    0           input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Conv1 (Conv2D)                  (None, 48, 48, 32)   864         Conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "... 311 layers ...\n",
      "__________________________________________________________________________________________________\n",
      "out_relu (ReLU)                 (None, 3, 3, 1280)   0           Conv_1_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_9 (Glo (None, 1280)         0           out_relu[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,257,984\n",
      "Trainable params: 2,223,872\n",
      "Non-trainable params: 34,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# MobileNetV2 is distributed under Apache License 2.0: https://github.com/tensorflow/models/blob/master/LICENSE\n",
    "base_model = tf.keras.applications.MobileNetV2(weights='imagenet', input_shape=(96, 96, 3), include_top=False, pooling='avg')\n",
    "C = Control_print()\n",
    "base_model.summary(print_fn=C.omitted_print)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "軽量とは言っても、およそ**300層**という、ここまでの講義で作ってきたネットワークに比べるとより深層なモデルです。これはImageNetのソース・ドメインを与えられて訓練されたモデルなわけですが、このモデルをターゲット・ドメイン＝CIFAR-10 への転移学習に使ってみましょう。転移学習のやり方にも色々ありますが、今回は単純に\n",
    "\n",
    "1. CIFAR-10の入力shape:(32, 32, 3) をリサイズ（拡大）して(96, 96, 3) にする\n",
    "2. MobileNetV2専用の前処理にかける\n",
    "3. これをMobileNetV2に入力し、1280次元の出力を得る\n",
    "4. 1280次元のベクトルから10次元ベクトルに`Dense`で変換し、softmax活性化\n",
    "\n",
    "でCIFAR-10の10クラス分類モデルを作ります。このモデルをCIFAR-10で訓練してみます。ただし、ここでは、計算時間削減のためMobileNetV2のパラメータはいじらず、4番の線形変換**のみ**訓練対象とします。以下のクラスが1~4の処理をするモデルの実装です："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TransferModel(tf.keras.Model): # モデル設計\n",
    "    def __init__(self, T=1):\n",
    "        super(TransferModel, self).__init__()\n",
    "        # MobileNetV2 is distributed under Apache License 2.0: https://github.com/tensorflow/models/blob/master/LICENSE\n",
    "        self.base_model = tf.keras.applications.MobileNetV2(weights='imagenet', input_shape=(96, 96, 3), include_top=False, pooling='avg')\n",
    "        self.l = tf.keras.layers.Dense(10)\n",
    "        self.sigma = tf.keras.layers.Activation('softmax')\n",
    "        self.base_model.trainable = False\n",
    "        self.T = 1\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = 255.0*x # MobileNetV2入力レンジは0~255で設定されているようです\n",
    "        h = tf.image.resize(x, (96, 96))\n",
    "        h = tf.keras.applications.mobilenet_v2.preprocess_input(h)\n",
    "        h = self.base_model(h)\n",
    "        h = self.l(h)\n",
    "        return self.sigma(h/self.T)\n",
    "    \n",
    "    def summary(self):\n",
    "        x = tf.keras.Input(shape=(32, 32, 3))\n",
    "        return (tf.keras.Model(inputs=x, outputs=self.call(x))).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">注意ですが、どうやら`tf.keras.Model`を継承して上のようにクラスで書くのは、keras Functional API（上での`summary`関数の再実装に使っている`model = tf.keras.Model(inputs, outputs)`のようにしてモデルを作る方法）に比べると、やや訓練速度が劣るようです。今回は説明の便宜上、上の実装にしました。`summary`関数で使っているので二度手間感がありますが…\n",
    "\n",
    "入力画素値は初めから0-255でも良かったのですが、今まで0-1に設定していたのでそれに合わせました。モデルのサマリーを見ると1から4の処理が行われているのが確認できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_18 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_mul_1 (TensorFlo [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_resize_5/ResizeB [(None, 96, 96, 3)]       0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_truediv_4 (Tenso [(None, 96, 96, 3)]       0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_sub_4 (TensorFlo [(None, 96, 96, 3)]       0         \n",
      "_________________________________________________________________\n",
      "mobilenetv2_1.00_96 (Model)  (None, 1280)              2257984   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                12810     \n",
      "=================================================================\n",
      "Total params: 2,270,794\n",
      "Trainable params: 12,810\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_tr = TransferModel()\n",
    "model_tr.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "早速訓練してみます。3エポック程度で十分です："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 40s 26ms/step - loss: 0.5264 - accuracy: 0.8217 - val_loss: 0.4284 - val_accuracy: 0.8506\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 39s 25ms/step - loss: 0.3894 - accuracy: 0.8679 - val_loss: 0.4253 - val_accuracy: 0.8570\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 39s 25ms/step - loss: 0.3555 - accuracy: 0.8763 - val_loss: 0.4122 - val_accuracy: 0.8588\n"
     ]
    }
   ],
   "source": [
    "model_tr.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "Hist= model_tr.fit(X, Y, epochs=3, verbose=1, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation精度が85%程度を達成するのがわかりますが、**これは[6-1](#6-1-まだ解説していないテクニック)にて作ったアンサンブル模型の精度~75%を大幅に更新しています**。これはMobileNetV2がImageNetをもちいた訓練の過程で、自然画像の判別に有用な特徴量を抽出するようになっているから可能になったと思われます。このように、ImageNetドメインから、上手くCIFAR-10ドメインに転移学習させることができました。\n",
    "> ここではいかにも高精度の分類器ができた！と言わんばかりなので補足しておきますが、調べてみると85%は2013年くらいの最高精度で、最近は99%周辺争いのようです。残念。\n",
    "\n",
    "### Fine tuning\n",
    "上のデモではソース・ドメインのモデルは一切変更せず（`self.base_model.trainable = False`）に最後の線形変換のみを訓練しましたが、ターゲット・ドメインのタスクを解く際に、ソース・ドメインのモデルパラメータを固定しなくても良いでしょう。こちらも更に上手く調整することをしばしば**ファインチューニング**と呼ぶようですが、今回は深入りしません。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### モデルの蒸留\n",
    "その代わりに、最後にモデルの蒸留（[arXiv:1503.02531](https://arxiv.org/abs/1503.02531)）と呼ばれるモデル軽量化のテクニックを説明します。ここまでで、MobileNetV2+Denceによる、巨大な（我々が作ったCIFAT-10分類器のなかでは最高精度の）モデルを手に入れたわけですが、いささか巨大過ぎるモデルは色々扱いに困ります。そこで、**より軽量な「生徒」モデルを、巨大な「教師モデル」を用いて訓練する**のはどうか、と考えてみます。たとえば以下のようなモデル：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 32, 32, 16)        448       \n",
      "_________________________________________________________________\n",
      "... 21 layers ...\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_truediv_3 (Tenso [(None, 10)]              0         \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 280,218\n",
      "Trainable params: 280,218\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = CNNModel()\n",
    "C = Control_print(fst=8, lst=29)\n",
    "model.summary(print_fn=C.omitted_print)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "を考えてみます。これはパラメータ数でいうと転移学習で作った「教師」モデルの1/10程度のモデルです。\n",
    "#### なぜ教師モデルを使うと良いと期待されるか\n",
    "分類問題をデータから解かせるとき、相互エントロピー誤差はデータ生成確率分布そのものではなく経験確率\n",
    "\n",
    "$$\n",
    "\\hat{p}_N({\\bf x}, y) = \\frac{1}{N} \\sum_{n=1}^N\n",
    " \\delta(y-y_n, {\\bf x} - {\\bf x}_n), \\quad\n",
    "\\hat{p}_N(y|{\\bf x}) = \\frac{\\hat{p}_N({\\bf x}, y)}{\\hat{p}_N({\\bf x})} \n",
    " $$\n",
    " \n",
    "を用いたモデル $q(y|{\\bf x})$ との KL距離\n",
    "\n",
    "$$\n",
    "D_{KL}(\\hat{p} \\| q) \\approx \\Big\\langle \\log \\frac{q(y|{\\bf x})}{\\hat{p}_N(y|{\\bf x})} \\Big\\rangle_{y \\sim \\hat{p}(y|{\\bf x}), {\\bf x} \\sim \\hat{p}_N({\\bf x})}\n",
    "$$\n",
    "\n",
    "に対応していたのでした。ここで、データそのものではなく「教師ネットワーク」$r(y|{\\bf x})$ を用いて $q$ を訓練するには、\n",
    "\n",
    "$$\n",
    "D_{KL}(r\\|q) \\approx \\Big\\langle \\log \\frac{q(y|{\\bf x})}{r(y|{\\bf x})} \\Big\\rangle_{y \\sim r(y|{\\bf x}), {\\bf x} \\sim \\hat{p}_N({\\bf x})}\n",
    "$$\n",
    "\n",
    "を $q$ を動かして減らすことに他なりません。これは $\\hat{p}_N$ が「正解のみ1他0」ということよりも明らかに多くの情報を $r$ が持っているはずだということです。例えば\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data answer: [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "teacher output: [2.3899720e-05 8.9168005e-08 1.6611683e-08 2.0855557e-08 2.8456734e-08\n",
      " 4.7532012e-10 3.6386442e-08 8.7007374e-10 9.9997592e-01 2.1505276e-08]\n"
     ]
    }
   ],
   "source": [
    "model_tr.trainable = False # 教師モデルは凍結しておく\n",
    "n = np.random.randint(len(Y_test))\n",
    "plt.imshow(X_test[n]); plt.show()\n",
    "print(\"data answer:\", one_hot(Y_test[n]))\n",
    "print(\"teacher output:\", prob(model_tr, X_test[n]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "を見ると、データの「答え」程の最大のシャープネスを教師ネットワークは持っていません。ほとんど1に近い出力の中でも、0ではない値がある部分が幾らかあり、そこが生徒ネットワークにとって、データの「答え」だけでは得られない**知識**になっている（これを**dark knowledge**と呼びます）というわけです。\n",
    "\n",
    "蒸留は、教師ネットワークの、文字通り**知識の蒸留**を試みるものです。知識の蒸留とはナンノコッチャ、という感じがしますが、もちろん化学における蒸留そのものではないわけですが、それに思想としてはかなり近いことをやります。\n",
    "\n",
    "基本的には教師ネットワークの出力を教師信号と読み替えた生徒モデルの教師あり学習を、相互エントロピー誤差を用いて行う\n",
    "> 実際はデータとの相互エントロピー誤差と教師ネットワークとの相互エントロピー誤差の2つを適当に重み付けしたものを使う用に思いますが、今回は簡略化で教師ネットワークとの誤差のみを用います。\n",
    "\n",
    "わけですが、ただこれをやるだけでは、折角ラベル毎に確率値が振られていても、どれかがほぼ1で他の値がすごく小さければ教師付きデータでの学習とあまり差が無くなってしまいます。それを避けるために**温度**を導入し、「高温からだんだんと冷やしていくことで知識を蒸留する」のがポイントです。そのために、モデルがsoftmax出力\n",
    "\n",
    "$$\n",
    "q(y_i = 1 | {\\bf x})=\n",
    "\\frac{e^{ v_i({\\bf x}) }}{\n",
    "\\sum_j e^{v_j({\\bf x})}}\n",
    "$$\n",
    "\n",
    "だとして、これを統計力学と考え、温度を導入します：\n",
    "\n",
    "$$\n",
    "q^T(y_i = 1 |{\\bf x})=\n",
    "\\frac{e^{ v_i({\\bf x})/T }}{\n",
    "\\sum_j\n",
    "e^{v_j({\\bf x})/T}}\n",
    "$$\n",
    "\n",
    "教師モデルも同様に温度入りのソフトマックス\n",
    "\n",
    "$$\n",
    "r^T(y_i=1|{\\bf x})=\n",
    "\\frac{e^{z_i({\\bf x})/T}}{\n",
    "\\sum_j\n",
    "e^{z_j({\\bf x})/T}\n",
    "}\n",
    "$$\n",
    "\n",
    "として、誤差関数\n",
    "\n",
    "$$\n",
    "L^T(q, {\\bf x}) = -\n",
    "\\sum_{i}\n",
    "r^T(y_i=1|{\\bf x})\n",
    "\\log {q^T(y_i=1|{\\bf x})}\n",
    "$$\n",
    "\n",
    "を使ったSGD更新を、初めは高温$T\\approx$大でやり、教師の知識が伝達しやすくしておき、徐々に低温に持っていきながら訓練を行うことでそれを洗練させると言う狙いです。実際にやってみましょう：\n",
    "\n",
    "#### 蒸留なし：これまで通りの普通の訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/8, T=1, val_accuracy:0.6096\n",
      "epoch 2/8, T=1, val_accuracy:0.6754\n",
      "epoch 3/8, T=1, val_accuracy:0.6788\n",
      "epoch 4/8, T=1, val_accuracy:0.7105\n",
      "epoch 5/8, T=1, val_accuracy:0.7194\n",
      "epoch 6/8, T=1, val_accuracy:0.7185\n",
      "epoch 7/8, T=1, val_accuracy:0.7238\n",
      "epoch 8/8, T=1, val_accuracy:0.717\n",
      "CPU times: user 38.5 s, sys: 2.45 s, total: 40.9 s\n",
      "Wall time: 35.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "L = tf.keras.losses.SparseCategoricalCrossentropy() # 誤差関数, Sparse...になっているのに注意、蒸留の場合は別のものを使う\n",
    "model = CNNModel()\n",
    "optimizer=tf.keras.optimizers.Adam()\n",
    "tf_batch_step = tf.function(batch_step)\n",
    "N_epoch = 8\n",
    "\n",
    "for epoch in range(N_epoch):\n",
    "    batch = return_tf_batch(X, Y, batch_size=38)\n",
    "    for (x,y) in batch:\n",
    "        loss_value = tf_batch_step(x, y, model, optimizer)\n",
    "    print(\"epoch {}/{}, T={}, val_accuracy:{}\".format(epoch+1, N_epoch, 1, measure(model, X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 蒸留あり："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/8, T=1.4e+01, val_accuracy:0.5717\n",
      "epoch 2/8, T=9.8, val_accuracy:0.6414\n",
      "epoch 3/8, T=6.9, val_accuracy:0.6854\n",
      "epoch 4/8, T=4.8, val_accuracy:0.7143\n",
      "epoch 5/8, T=3.4, val_accuracy:0.7242\n",
      "epoch 6/8, T=2.4, val_accuracy:0.7274\n",
      "epoch 7/8, T=1.6, val_accuracy:0.7507\n",
      "epoch 8/8, T=1.2, val_accuracy:0.7484\n",
      "Wall time: 1e+02 s\n"
     ]
    }
   ],
   "source": [
    "#%%time forループ中でtf.functionを使うと、timeマジックコマンドとなぜか競合する…\n",
    "import time\n",
    "t0 = time.time()\n",
    "L = tf.keras.losses.CategoricalCrossentropy(from_logits=False) # 誤差関数\n",
    "model = CNNModel()\n",
    "optimizer=tf.keras.optimizers.Adam()\n",
    "tf_batch_step = tf.function(batch_step)\n",
    "T, decay = 20, 0.7\n",
    "N_epoch = 8\n",
    "\n",
    "for epoch in range(N_epoch):\n",
    "    batch = return_tf_batch(X, Y, batch_size=38)\n",
    "    T = T*decay    # 温度をエポック毎に下げていく処理\n",
    "    model_tr.T = T # 教師モデルの温度を今の温度に設定\n",
    "    model.T = T    # 生徒モデルの温度を今の温度に設定\n",
    "    teacher = tf.function(lambda x: model_tr(x, training=False))# これをやらないと圧倒的に遅くなる\n",
    "    for (x,_) in batch:\n",
    "        y = teacher(x) # 教師信号はデータではなく、教師ネットワークの出力値\n",
    "        loss_value = tf_batch_step(x, y, model, optimizer) \n",
    "    print(\"epoch {}/{}, T={:.2}, val_accuracy:{}\".format(epoch+1, N_epoch, T, measure(model, X_test, Y_test)))\n",
    "t1 = time.time(); print(\"Wall time: {:.1} s\".format(t1-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このように、蒸留したほうが精度が良くなります。ただし訓練にかかる時間は、教師ネットワークが巨大なため、教師信号を得るところがボトルネックになっているのに注意。とくに、教師ネットワークを用いて教師信号を作るところで時間を食いますから、`tf.function()`で一旦囲って使ったほうが良いです。これをやるのとやらないので全然かかる時間が違います（ただし、これで教師モデルの温度変更がきちんと反映されているかはチェックしていません）。また、ここでは転移学習で得たモデルを教師としましたが、アンサンブルを教師にするなど色々考えられると思います。\n",
    "\n",
    "#### Born again Neural Network\n",
    "このように知識の蒸留は基本的には、教師モデルよりも軽量な生徒モデルを作ることが主眼だったわけですが、[arXiv:1805.04770](https://arxiv.org/abs/1805.04770)では**教師モデル構造＝生徒モデル構造**として、2回同じ構造のネットワークを\n",
    "1. 1回目は普通に教師あり学習させ、得たモデルを教師モデルとし\n",
    "2. 2回目は教師モデルのdark knowledgeを用いて同じ構造の生徒モデルを訓練する\n",
    "\n",
    "ということをやると、なんと**生徒モデルのほうが汎化性能が上がる場合がある**ことを報告しており、これを「Born Again Neural Network」とよんでいます。これはなかなか驚きでした。\n",
    "\n",
    "#### Defensive distillation\n",
    "また、蒸留して作られたモデルはadversarial attackに対して強くなっているらしいです（[arXiv:1511.04508](https://arxiv.org/abs/1511.04508)）これは、蒸留をすると序盤で高温下での訓練をするわけですが、JSMAアタックに使うための勾配出力が概ね$1/T$倍の修正を受けるため、脆弱なピクセルが出来づらいということらしいです。ここで実際に実験できましたが、割愛します。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
