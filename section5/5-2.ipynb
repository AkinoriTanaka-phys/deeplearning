{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "mnist = tf.keras.datasets.mnist \n",
    "(x_mnist_train, y_mnist_train), (x_mnist_test, y_mnist_test) = mnist.load_data()\n",
    "x_mnist_train, x_mnist_test = x_mnist_train / 255.0, x_mnist_test / 255.0\n",
    "train_images = x_mnist_train.reshape((60000, 28, 28, 1))\n",
    "train_labels = y_mnist_train.reshape((60000, 1))\n",
    "test_images = x_mnist_test.reshape((10000, 28, 28, 1))\n",
    "test_labels = y_mnist_test.reshape((10000, 1))\n",
    "\n",
    "def train(model, epochs=1):\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    model.fit(train_images, train_labels, epochs=epochs, validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-2. スキップ接続\n",
    "ここまで、リカレントニューラルネット以外では基本的には\n",
    "\n",
    "![alt](forward.jpg)\n",
    "\n",
    "のような**順番に伝搬してゆく** ネットワーク構造を考えていましたが、ニューラルネットワークをそのようにしか作ってはいけないわけではありません。勾配の自動計算にはグラフ構造があれば十分なので、\n",
    "\n",
    "![alt](skip.jpg)\n",
    "\n",
    "のようなネットワーク構造を考えても良いのです。このような構造は**スキップ接続(skip connections)** と呼ばれます。まず簡単なスキップ接続として\n",
    "\n",
    "$$\n",
    "h = \\sigma(z) + z\n",
    "$$\n",
    "\n",
    "を考えてみます。ここで $\\sigma$ は何らかの非線形関数 (sigmoidやrelu)とします。この出力 $h$ の 入力 $z$ についての微分値は当たり前ですが\n",
    "\n",
    "$$\n",
    "\\frac{d h}{dz} = \\sigma'(z) + 1\n",
    "$$\n",
    "\n",
    "となります。$\\sigma$ がsigmoid関数やrelu関数の場合、スキップなしの場合 $\\sigma'(z)$ はすごく小さい値になりがちですが、スキップ有りの場合、これに $+1$ が加わるので、勾配が大きくなります。誤差関数 $L$ を $h$ の関数と見ると、\n",
    "\n",
    "$$\n",
    "\\frac{dL}{dz} = \\frac{dL}{dh} \\frac{d h}{dz}\n",
    "$$\n",
    "\n",
    "なので、誤差関数の勾配も大きくなってSGD訓練がはかどりそうです。とくにreluの場合、オフセットよりも小さな値は**ゼロ** なので、順番にベクトルを重ねるネットワークだと**情報が落ちていってしまいます**。それに比べ、スキップ接続は入力の情報量を減らしません。ここでは幾つかのスキップ接続を紹介します。\n",
    "\n",
    "### Residual network\n",
    "スキップ接続を持つネットワークで有名なのが [arXiv:1512.03385](https://arxiv.org/abs/1512.03385) の**残差ネットワーク(Residual network, ResNet)** です。これは超深層ネットワーク（**~$10^{2 \\sim 3}$層**）の訓練のために導入された**残差ブロック(Residual Block, ResBlock)** という構成要素(モジュール)を新たに提唱した論文でもあります。超深層ではない場合にも残差ブロックを使ったネットワークがしばしば使われますので、ここで説明しておいて損はないでしょう。\n",
    "\n",
    "#### 素朴なResBlock\n",
    "論文では畳み込みを前提としたResBlockを使っていますが、\n",
    "まずは畳込みではなく、ベクトルを処理してゆく形式で最も単純なResBlockを作ってみます：\n",
    "\n",
    "![alt](resblock1.jpg)\n",
    "\n",
    "$$\n",
    "{\\bf y} = \\sigma({\\color{red}{W}}{\\bf x} + {\\color{red}{\\bf b}})  + {\\bf x}\n",
    "$$\n",
    "\n",
    "の形のものです。この処理1ブロックを新たなネットワークの「部品」と考えます。tenforflowでは `tf.keras.layers.Layer` を継承したクラスを定義すれば他の便利機能と一緒に使えるので便利です。定義には\n",
    "* `__init__(self)`: クラス初期化関数\n",
    "* `call(self, inputs)`: 層の入力 `inputs` が入ってきたときの出力\n",
    "\n",
    "が最低限あれば良いです。例えば以下のように書けばよいです："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       "array([[1.2919633 , 0.94248337, 0.7971257 , 1.4403968 , 0.5051593 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DenseResBlock1_pre(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(DenseResBlock1_pre, self).__init__()\n",
    "        self.f = tf.keras.layers.Dense(units, activation='sigmoid')        \n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return self.f(inputs) + inputs\n",
    "    \n",
    "x = tf.random.uniform(shape=[1, 5])\n",
    "ResBlock = DenseResBlock1_pre(units=5)\n",
    "ResBlock(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上の例では 5次元ベクトル ${\\bf x}$ に作用させるResBlockを書きました。ここで実装上のテクニックなのですが、${\\bf y} = \\sigma({\\color{red}{W}}{\\bf x} + {\\color{red}{\\bf b}})  + {\\bf x}$ のベクトル和が定義できるためには、用意する ${\\color{red}{W, {\\bf b}}}$ による線形変換が ${\\bf x}$ と同じ次元のベクトルを返さねばなりません。このため、上の実装で `x = tf.random.uniform(shape=[1, 5])`となっているところを適当な別のshapeに取るとエラーが出てしまいます。ここの処理は実は **自動化** できます。それをするには\n",
    "* `__init__(self)` にはパラメータ読み込みを書かず、super関数による初期化だけ書く\n",
    "* 訓練パラメータは代わりに`build(self, input_shape)`で定義する\n",
    "\n",
    "とすれば良いです。この`build`というのはそのLayerオブジェクトが呼ばれて実際にベクトルの処理をしたときに実行される関数ですので、入寮ベクトルのサイズをわざわざ指定しなくても良くなります："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 6), dtype=float32, numpy=\n",
       "array([[1.1218925 , 0.3582188 , 0.8069558 , 1.5057303 , 0.89166486,\n",
       "        1.4005613 ]], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DenseResBlock1(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(DenseResBlock1, self).__init__()\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        units = input_shape[-1] # input_shape = (batchsize, dim_of_vector), and input_shape[-1] = dim_of_vector\n",
    "        self.f = tf.keras.layers.Dense(units, activation='sigmoid')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return self.f(inputs) + inputs\n",
    "    \n",
    "x = tf.random.uniform(shape=[1, 6])\n",
    "ResBlock = DenseResBlock1()\n",
    "ResBlock(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 素朴なResBlockその2\n",
    "上の例では ${\\bf x}$ と $\\sigma(W{\\bf x} + {\\bf b})$ をベクトルとして足し合わせるために同じ次元にしなければいけなかったわけですが、必ずしもそういうわけではなく、以下のようなスキップ構造を考えることもできます：\n",
    "\n",
    "![alt](resblock2.jpg)\n",
    "\n",
    "$$\n",
    "{\\bf y} = \\sigma({\\color{red}{W_1}}{\\bf x} + {\\color{red}{\\bf b}})  + {\\color{red}{W_2}}{\\bf x}\n",
    "$$\n",
    "\n",
    "これも作れます。こちらは出力先を指定すればよいので`build`関数は必要ないです（というか`tf.keras.layers.Dense`に`build`が定義されているのだと思います）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[0.02537549, 0.5109363 , 1.3208609 ]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DenseResBlock2(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(DenseResBlock2, self).__init__()\n",
    "        self.f1 = tf.keras.layers.Dense(units, activation='sigmoid')\n",
    "        self.w2 = tf.keras.layers.Dense(units, use_bias=False)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return self.f1(inputs) + self.w2(inputs)\n",
    "    \n",
    "x = tf.random.uniform(shape=[1, 6])\n",
    "ResBlock = DenseResBlock2(units=3)\n",
    "ResBlock(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定義したblockを使う\n",
    "いままでの`tf.keras.layers.Layer`クラスと同じように使えます。例えばアヤメデータの訓練をResNetでやってみます：\n",
    "\n",
    "> 注意ですが、一層目での`input_shape`の引数をここまでのResBlockでは定義して来ませんでした。これは無くても動く（つまり以下のコードで一層目を削除しても訓練は進む）ようですが、`model.summary()`で上手く中間での出力を出してくれません。このあたりまで自動化する場合はやはりBlackの`build()`関数にその処理を書くべきなのだと思います。\n",
    "\n",
    "以下のようなモデルを作ってみました。\n",
    "\n",
    "![alt](resnet.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 10)                50        \n",
      "_________________________________________________________________\n",
      "dense_res_block1_1 (DenseRes (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_res_block2_1 (DenseRes (None, 3)                 63        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 3)                 12        \n",
      "=================================================================\n",
      "Total params: 235\n",
      "Trainable params: 235\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 120 samples, validate on 30 samples\n",
      "Epoch 1/5\n",
      "120/120 [==============================] - 1s 4ms/sample - loss: 0.9740 - val_loss: 1.7219\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/5\n",
      "120/120 [==============================] - 0s 415us/sample - loss: 0.9480 - val_loss: 1.7539\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 3/5\n",
      "120/120 [==============================] - 0s 425us/sample - loss: 0.9324 - val_loss: 1.8035\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 4/5\n",
      "120/120 [==============================] - 0s 373us/sample - loss: 0.9133 - val_loss: 1.8285\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 5/5\n",
      "120/120 [==============================] - 0s 456us/sample - loss: 0.8980 - val_loss: 1.8398\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris() # アヤメデータ読み込み\n",
    "X_train, Y_train = iris.data, iris.target\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "                                    tf.keras.layers.Dense(10, input_shape=(4,), activation='relu'),\n",
    "                                    DenseResBlock1(),          # ここに挟んだ\n",
    "                                    DenseResBlock2(units=3), # ここに挟んだ\n",
    "                                    tf.keras.layers.Dense(3, activation='softmax')\n",
    "                                   ])\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "hist = model.fit(X_train, Y_train, epochs=5, batch_size=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 素朴な畳み込みResBlock\n",
    "畳み込み演算に対するResBlockはチャネル方向を一単位にしてスキップ構造を作ります。ベクトルの成分をそのままチャネル成分に置き換えて図を描くと\n",
    "\n",
    "![alt](resblock3.jpg)\n",
    "\n",
    "こんな感じになります。`Dense`を`Conv2D`に置き換えて、画像サイズを保つようにしておけば同じように実装できます：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 28, 28, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyResBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, kernel_size, activation):\n",
    "        super(MyResBlock, self).__init__()\n",
    "        self.kernel_size = kernel_size # \n",
    "        self.activation = activation   # ここではじめに設定を読み込んでおくとよい\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        channels = input_shape[-1] # input_shape = (batchsize, Lx, Ly, channels), and input_shape[-1] = channels\n",
    "        self.f = tf.keras.layers.Conv2D(channels, self.kernel_size, padding='same', activation=self.activation)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return self.f(inputs) + inputs\n",
    "    \n",
    "x = tf.random.uniform(shape=[2, 28, 28, 3])\n",
    "ResBlock = MyResBlock((3,3), activation='relu')\n",
    "ResBlock(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 論文のResBlockその1\n",
    "論文 [arXiv:1512.03385](https://arxiv.org/abs/1512.03385) で導入されたResBlockは2つあります。まず最初のものは\n",
    "\n",
    "![alt](resblock4.jpg)\n",
    "\n",
    "のように、スキップ内部に 畳み込み-relu-畳み込みを挟んで、最後に合算した後ふたたびrelu、というものです："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 28, 28, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ResBlock1(tf.keras.layers.Layer):\n",
    "    def __init__(self, kernel_size=(3,3)):\n",
    "        super(ResBlock1, self).__init__()\n",
    "        self.kernel_size = kernel_size # \n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        channels = input_shape[-1] # input_shape = (batchsize, Lx, Ly, channels), and input_shape[-1] = channels\n",
    "        self.conv1 = tf.keras.layers.Conv2D(channels, self.kernel_size, padding='same')\n",
    "        self.conv2 = tf.keras.layers.Conv2D(channels, self.kernel_size, padding='same')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        h = self.conv1(inputs)\n",
    "        h = tf.keras.activations.relu(h)\n",
    "        h = self.conv2(h)\n",
    "        h = h + inputs\n",
    "        return tf.keras.activations.relu(h)\n",
    "    \n",
    "x = tf.random.uniform(shape=[2, 28, 28, 3])\n",
    "ResBlock = ResBlock1()\n",
    "ResBlock(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実際にMNISTを想定したモデルを構築してみましょう："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "res_block1_1 (ResBlock1)     (None, 5, 5, 64)          73856     \n",
      "_________________________________________________________________\n",
      "res_block1_2 (ResBlock1)     (None, 5, 5, 64)          73856     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                102464    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 269,642\n",
      "Trainable params: 269,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model(SkipConnection):\n",
    "    '''\n",
    "     MNIST用に前回作ったネットワークの畳み込み最終層に SkipConnection レイヤーを2回繰り返したモデル\n",
    "    '''\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add(SkipConnection()) # ここで2回 inception を繰り返す\n",
    "    model.add(SkipConnection()) # ここで2回 inception を繰り返す\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "model = build_model(ResBlock1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1エポックだけ訓練してみます："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "60000/60000 [==============================] - 7s 115us/sample - loss: 0.1253 - accuracy: 0.9623 - val_loss: 0.0374 - val_accuracy: 0.9881\n"
     ]
    }
   ],
   "source": [
    "train(model, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ただしこのResBlockは、チャネル数 $c$ が大きくなると上の経路でずっとそのチャネル数ぶんの処理、例えばフィルターは毎回$2c^2$毎用意しなくてはならないなど、が発生するため、メモリを食ってしまう場合があります。そこで提案された二つ目のResBlockが以下です。\n",
    "\n",
    "#### 論文のResBlockその2：ボトルネック型\n",
    "アイデアは簡単で、要はチャネル数を減らしてしまえばよいのですから、\n",
    "\n",
    "![alt](resblock5.jpg)\n",
    "\n",
    "のように、一旦チャネル数を畳み込みの中でも一番計算量の少ない1x1畳み込みで減らし（論文では入力チャネルの1/4）、少ないチャネルで望むサイズの畳み込み演算をし、再び1x1畳み込みで元のチャネルサイズに戻すというものです：\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "res_block2 (ResBlock2)       (None, 5, 5, 64)          4875      \n",
      "_________________________________________________________________\n",
      "res_block2_1 (ResBlock2)     (None, 5, 5, 64)          4875      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                102464    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 131,680\n",
      "Trainable params: 131,680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class ResBlock2(tf.keras.layers.Layer):\n",
    "    def __init__(self, kernel_size=(3,3)):\n",
    "        super(ResBlock2, self).__init__()\n",
    "        self.kernel_size = kernel_size # \n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        channels = input_shape[-1] # input_shape = (batchsize, Lx, Ly, channels), and input_shape[-1] = channels\n",
    "        self.conv_1x1_before = tf.keras.layers.Conv2D(channels//4+1, (1,1), padding='same', activation='relu')\n",
    "        self.conv = tf.keras.layers.Conv2D(channels//4+1, self.kernel_size, padding='same', activation='relu')\n",
    "        self.conv_1x1_after = tf.keras.layers.Conv2D(channels, (1,1), padding='same')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        h = self.conv_1x1_before(inputs)\n",
    "        h = self.conv(h)\n",
    "        h = self.conv_1x1_after(h)\n",
    "        h = h + inputs\n",
    "        return tf.keras.activations.relu(h)\n",
    "    \n",
    "model = build_model(ResBlock2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確かに`ResBlock1` に比べて `Param #` が減っていることがわかります。訓練もしてみましょう："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "60000/60000 [==============================] - 8s 128us/sample - loss: 0.1384 - accuracy: 0.9565 - val_loss: 0.0470 - val_accuracy: 0.9854\n"
     ]
    }
   ],
   "source": [
    "train(model, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### なぜResBlockが良いのか？\n",
    "深層学習では、ImageNetと呼ばれる大規模画像データを用いた画像認識コンペの最高性能(State-Of-The-Art, SOTAと略されることもあります)がネットワークの深層化とともに毎年更新されている時期で、2014年の優勝モデルの一つが次に紹介するInceptionを搭載したGoogLeNetで、22層, 誤認識率6.7%でした。これに対しResNetは2015年の優勝モデルであり、これは驚きの**152 層, 誤認識率 3.57%** でした。上に挙げたResNetの論文の冒頭で述べられていますが、あまりに深層になりすぎると、スキップ接続のないニューラルネットは深層化すると性能が悪く見えだす傾向があることが知られていました。これはAICなどの古典的なオッカムの剃刀原理に基づく素朴な期待：データのサイズに対しいたずらに巨大なモデルは汎化しない、の傍証のようにも思われるかもしれませんが、この論文では**スキップ接続がそのような深層化に伴う問題を解消する** と主張しています。\n",
    "\n",
    "その理由はなぜか、というのは冒頭でコメントした勾配の伝搬も考えられますが、やはり理論的な決定打は無いように思われます（もしどなたかご存知なら教えて下さい！）。ここでは幾つかの論文についてコメントしておきます。\n",
    "\n",
    "まずResBlockをベースにモデルを作ると、入力 $\\to$ 出力の経路数が層数について指数的に増大していくのがわかります。各経路を別々のネットワークと考えると**アンサンブル学習** をやっているようにも思えます。この仮説は [arXiv:1605.06431](https://arxiv.org/abs/1605.06431) にて調べられ、例えば訓練後にスキップ経路を遮断すると精度が落ちるなどの傍証が確認されたようです。\n",
    "\n",
    "また、汎化性能との兼ね合いで [**Flat minima**](https://www.mitpressjournals.org/doi/abs/10.1162/neco.1997.9.1.1) という考え方が昔からあります。これは「汎化するパラメータの周辺は経験誤差の局面がフラットになっているだろう」ということなのですが、この説もはっきり正しいとはまだわからないのですが、実際に誤差関数を2+1次元に可視化する([arXiv:1712.09913](https://arxiv.org/abs/1712.09913))とスキップ接続がある場合はない場合に比べ、誤差関数が滑らかなランドスケープを持つ傾向があるらしく、Flat minimaを思わせます。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inception\n",
    "Inceptionは厳密に言えば上で説明したようなスキップ接続ではないのですが、似た構造を持っている有名なネットワークです。もとは[arXiv:1409.4842](https://arxiv.org/abs/1409.4842) で提案され、[arXiv:1512.00567](https://arxiv.org/abs/1512.00567)で更に改良されました。まずは一番素朴なinceptionモジュール層の構造を絵で描いてみます：\n",
    "\n",
    "![alt](inception1.jpg)\n",
    "\n",
    "${\\color{red}{\\text{conv}}}$ は畳み込み、${\\color{blue}{\\text{pool}}}$ はプーリングを表します。これらの演算は画像サイズを変えないようにうまく調整させます（詳しくは後述の実装参照）。$\\text{concat}$ はそれぞれの経路の出力チャネルをすべてチャネル方向に統合して一つの大きなチャネルから成るテンソルと見なす操作（図では各畳込みの出力チャネル $c\\_\\text{out} = 2$, 入力チャネル $=3$なので、2,2,2,3チャネルの画像を 9チャネルにまとめ直す操作 ）です。\n",
    "\n",
    "畳み込みニューラルネットワークでは、層ごとに「畳み込み演算をすべきか、プーリングすべきか」の設計を迫られる上、「それぞれのカーネルサイズをどうすべきか」なども自由度があるわけですが、inceptionがやっているのは身も蓋もない言い方をすると、**どれが良いかわからないから全部載せ** している状態です。それぞれのサブ演算で、絵ではチャネル数を全て2にして描きましたが、チャネル数を変える自由度はあります。また、この層の出力は全てのサブ演算で画像サイズを合わせます。これはゼロパディングなどで達成されます。また、プーリングは通常カーネルサイズ＝ストライドサイズ、なのですがここではプーリング結果も他のサブ演算と画像出力がおなじになるようにストライドを取ります。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class InceptionBlock1(tf.keras.layers.Layer):\n",
    "    def __init__(self, c_out=64):\n",
    "        super(InceptionBlock1, self).__init__()\n",
    "        self.conv_1x1 = tf.keras.layers.Conv2D(c_out, (1, 1), padding='same', activation='relu')\n",
    "        self.conv_3x3 = tf.keras.layers.Conv2D(c_out, (3, 3), padding='same', activation='relu')\n",
    "        self.conv_5x5 = tf.keras.layers.Conv2D(c_out, (5, 5), padding='same', activation='relu')\n",
    "        self.pool_3x3 = tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(1,1), padding='same')\n",
    "        self.concat = tf.keras.layers.Concatenate()\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        c1 = self.conv_1x1(inputs)\n",
    "        c3 = self.conv_3x3(inputs)\n",
    "        c5 = self.conv_5x5(inputs)\n",
    "        p3 = self.pool_3x3(inputs)\n",
    "        return self.concat([c1, c3, c5, p3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "試しに以下のようなモデルにMNISTの分類をさせてみます："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "inception_block1 (InceptionB (None, 5, 5, 256)         143552    \n",
      "_________________________________________________________________\n",
      "inception_block1_1 (Inceptio (None, 5, 5, 448)         573632    \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 11200)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                716864    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 1,453,514\n",
      "Trainable params: 1,453,514\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(InceptionBlock1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まず、`c_out = 64` が一つの畳込み演算あたりの出力チャネル数なので、1x1, 3x3, 5x5の畳み込みでそれぞれ64チャネルが生成されます。従って、ここでの `naive_inception_module` の出力チャネル数は\n",
    "\n",
    "$$\n",
    "\\underbrace{64 \\times 3}_{192} + \\# \\text{input channels}\n",
    "$$\n",
    "\n",
    "になる筈です。一つ目のinceptionの入力は直前の出力の型 `Output Shape = (None, 5, 5, 64)` なので、64チャネルとわかります。従って 192+64 = 256 が一つ目のinceptionの出力チャネルとなります。これは二つ目のinceptionの入力になるが、同じ式から二つ目inceptionの出力チャネル数は 192+256 = 448 となっており、たしかに狙った操作ができている事がわかります。\n",
    "\n",
    "1エポックだけ適当なバッチサイズで訓練してみます："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "60000/60000 [==============================] - 8s 137us/sample - loss: 0.1192 - accuracy: 0.9625 - val_loss: 0.0326 - val_accuracy: 0.9901\n"
     ]
    }
   ],
   "source": [
    "train(model, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 改良その1\n",
    "ところで、上で作った素朴なInceptionモジュールは、どんどんチャネル数を増大させてゆく構造を持つため、重ねれば重ねるだけ訓練パラメータが増えて、メモリを食うのがわかります。そこでまず初めの論文 [arXiv:1409.4842](https://arxiv.org/abs/1409.4842) で提案されたのが、**更に1x1畳み込みを3x3, 5x5畳み込みの前に挿入し、そこのチャネル数を減らす**というものです。絵で描くと以下のようなモジュールを考えます：\n",
    "\n",
    "![alt](inception2.jpg)\n",
    "\n",
    "点線で囲った部分が素朴なinceptionと異なる部分です。3x3と5x5の畳み込み演算の直前に1x1の畳み込みを入れる理由は2つあります：\n",
    "* ボトルネックによる計算量の削減\n",
    "* 1x1畳み込みによる **network-in-network** 効果\n",
    "\n",
    "まずボトルネック効果ですが、図では最初の2つの1x1畳み込みの出力チャネル数を1として描いています。こうしておくと続く畳み込み演算で容易すべきフィルターの数が減るため、ネットワークのパラメータ数が減ります。入力チャネルが巨大になっても、このように中間でチャネル数を減らしておけばチャネル数爆発しても、計算量を抑えられると期待できます。\n",
    "\n",
    "もう一つの効果は、既に畳み込みの節でコメントしましたが、1x1畳み込みは、ピクセルに対してのミニネットワークを構成しているとも考えられます。これは [arXiv:1312.4400](https://arxiv.org/abs/1312.4400) にて提案された **network-in-network** と呼ばれる構造になっており、画像の一つの領域に多数のクラスター構造があると見つけやすい性質があるらしいです。\n",
    "> 蛇足ですが inceptionとはハリウッド映画のタイトルでもあり、これには「夢の中で夢を見る」というシーンがあるのですが、network-in-networkにかけたダジャレなのでしょうか？\n",
    "\n",
    "実装に行く前に、やはりこの場合でも出力チャネル数はそれぞれの経路で必ずしも同じ値でなくてよく、任意の値に取れることをコメントしておきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class InceptionBlock2(tf.keras.layers.Layer):\n",
    "    def __init__(self, c_out=64, c_bottleneck=1):\n",
    "        super(InceptionBlock2, self).__init__()\n",
    "        self.conv_1x1 = tf.keras.layers.Conv2D(c_out, (1, 1), padding='same', activation='relu')\n",
    "        #\n",
    "        self.conv_1x1_before3x3 = tf.keras.layers.Conv2D(c_bottleneck, (1, 1), padding='same', activation='relu')\n",
    "        self.conv_3x3 = tf.keras.layers.Conv2D(c_out, (3, 3), padding='same', activation='relu')\n",
    "        #\n",
    "        self.conv_1x1_before5x5 = tf.keras.layers.Conv2D(c_bottleneck, (1, 1), padding='same', activation='relu')\n",
    "        self.conv_5x5 = tf.keras.layers.Conv2D(c_out, (5, 5), padding='same', activation='relu')\n",
    "        #\n",
    "        self.pool_3x3 = tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(1,1), padding='same')\n",
    "        self.conv_1x1_afterpool = tf.keras.layers.Conv2D(c_out, (1, 1), padding='same', activation='relu')\n",
    "        #\n",
    "        self.concat = tf.keras.layers.Concatenate()\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        c1 = self.conv_1x1(inputs)\n",
    "        c3 = self.conv_3x3(self.conv_1x1_before3x3(inputs))\n",
    "        c5 = self.conv_5x5(self.conv_1x1_before5x5(inputs))\n",
    "        p3 = self.conv_1x1_afterpool(self.pool_3x3(inputs))\n",
    "        return self.concat([c1, c3, c5, p3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST分類させてみましょう。まず素朴なInceptionをで実験したモデルで、Inceptionモジュール部分だけ改良したバージョンのモデルを作るのは以下です。`c_bottleneck`はボトルネックのチャネル数です。絞りすぎですが、今回は計算量の削減効果をみるため `1` に取りましょう："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "inception_block2 (InceptionB (None, 5, 5, 256)         10754     \n",
      "_________________________________________________________________\n",
      "inception_block2_1 (Inceptio (None, 5, 5, 256)         35714     \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                409664    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 475,598\n",
      "Trainable params: 475,598\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(InceptionBlock2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "素朴なInceptionを用いた場合とパラメータ数を比べると劇的に減っているのがわかります。また、出力チャネル数も減っていますが、これはプーリング経路に1x1畳み込みを追加した効果です。では1エポック訓練させましょう："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "60000/60000 [==============================] - 10s 173us/sample - loss: 0.1346 - accuracy: 0.9579 - val_loss: 0.0496 - val_accuracy: 0.9832\n"
     ]
    }
   ],
   "source": [
    "train(model, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 改良その2\n",
    "改良その1が初めの論文 [arXiv:1409.4842](https://arxiv.org/abs/1409.4842) で説明された改良なのですが、この論文ではInceptionモジュールをどのように積み重ねるかのモデル（GoogLeNetと呼ばれる）の工夫も見られ、このモデルを他のサイズの画像などにも応用したい場合、調整が必要です。[arXiv:1512.00567](https://arxiv.org/abs/1512.00567) ではそのような応用に向けたさらなるInceptionモジュールの改良を行っています。ここでは僕が力尽きてきたためやりません（すいません）が、興味のある方は一読し、わかったら教えていただきたいです。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
